{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details for the project structure: \n",
    "1.   Project documentation\n",
    "1.1. design document\n",
    "1.2. run instructions (env, commands)\n",
    "1.3. architecture, losses, metrics\n",
    "2.   Data set \n",
    "3.   Model training code.\n",
    "3.1. Jupyter Notebook \n",
    "3.2. MLFlow project \n",
    "4.   Service deployment and usage instructions \n",
    "4.1. dockerfile or docker-compose file \n",
    "4.2. required services: databases \n",
    "4.3. client for service \n",
    "4.4. model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design principles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I would like to create simple question answering bot, using the Cornell movie dialogs corpus, and using Seq2Seq with attention model.\n",
    "Trained model consisting of Encoder and Decoder models will be trained on dataset, model weights will be saved according with word2id dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model description"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input: string variable length\n",
    "Output: string variable length\n",
    "\n",
    "Model will be the sequence-to-sequence (seq2seq) with attention, based on paper https://arxiv.org/abs/1409.3215 \n",
    "The encoder model consists of an embedding layer and lstm, the task of which is to transform a question encoded through the Word2id dictionary into a vector representation. Then, based on the obtained vector representation, the Decoder model consisting of an embedding layer, a GRUcell, an attention mechanism and an output fully connected layer turns this into a answer, which is decoded through the id2word dictionary.\n",
    "Embedding size was choosen as 256\n",
    "Hidden size was equal 512\n",
    "As loss function nn.CrossEntropyLoss() was used. \n",
    "I couldn't come up with any metric to evaluate the generated answer, so I just printed out the answer and saw if it made any sense, when I liked the response, I trained the network a little more and then stopped. I know its a weird approach, but in short time I didnt find anything better ;) And actually it work well."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the deployment I choose async architecture based on Flask, Celery and Redis as query DB. \n",
    "Service will be divided into parts: \n",
    "1. backend - which will perform the model inference according with the text processing utils. (on port 8080)\n",
    "2. frontend - simple streamlit app with text input field and button (on port 8501)\n",
    "3. Celery worker. \n",
    "4. Redis DB(port 6379)\n",
    "Each part should be placed in their own docker container and all containers will be linked through docker-compose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running instructions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "using terminal type:\n",
    "docker-compose up -d --build\n",
    "docker-compose up\n",
    "open the browser network URL: http://192.168.0.137:8501 or http://localhost:8501\n",
    "you can type your question in text input field and press Enter or click Ask button, and service will give you answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset description"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset\n",
    "Cornell movie dialogs corpus consists of 220,579 conversational exchanges between 10,292 pairs of movie characters, involves 9,035 characters from 617 movies, and in total 304,713 utterances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model training code provided in folder Train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
