{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import codecs\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"
     ]
    }
   ],
   "source": [
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "\n",
    "datafile = os.path.join(corpus_name, \"movie_lines.txt\")\n",
    "\n",
    "with open(datafile, 'rb') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "for line in lines[:10]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = os.path.join(corpus_name, \"formatted_movie_lines.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocess data - lower</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(datafile, encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what s a synonym for throbbing ?',\n",
       " 'sarah lawrence is on the other side of the country .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[456]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [[pair[0].split(), pair[1].split()] for pair in pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Выкинем слишком длинные предложения</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = 16\n",
    "pairs = [pair for pair in pairs if len(pair[0]) <= min_length and len(pair[1]) <= min_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126591"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train Test Split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "random.shuffle(pairs)\n",
    "idx = int(len(pairs) * test_size)\n",
    "\n",
    "train_pairs, test_pairs = pairs[idx:], pairs[:idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113932, 12659)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs), len(test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Count words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count = Counter()\n",
    "\n",
    "for pair in train_pairs:\n",
    "    for word in pair[0]:\n",
    "        word_count[word] += 1\n",
    "    for word in pair[1]:\n",
    "        word_count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Word to Id</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 10\n",
    "\n",
    "\n",
    "pad_idx = 0\n",
    "unk_idx = 1\n",
    "sos_idx = 2\n",
    "eos_idx = 3\n",
    "\n",
    "word2id = {\n",
    "    \"<pad>\": pad_idx,\n",
    "    \"<unk>\": unk_idx,\n",
    "    \"<sos>\": sos_idx,\n",
    "    \"<eos>\": eos_idx,\n",
    "}\n",
    "\n",
    "i = 4\n",
    "for word, count in word_count.items():\n",
    "    if count >= min_freq:\n",
    "        word2id[word] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5785"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tokenize</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = [], []\n",
    "    \n",
    "for pair in train_pairs:\n",
    "    train_data.append([\n",
    "        [word2id.get(word, unk_idx) for word in pair[0]],\n",
    "        [word2id.get(word, unk_idx) for word in pair[1]],\n",
    "    ])\n",
    "    \n",
    "for pair in test_pairs:\n",
    "    test_data.append([\n",
    "        [word2id.get(word, unk_idx) for word in pair[0]],\n",
    "        [word2id.get(word, unk_idx) for word in pair[1]],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[24, 63, 97, 302, 42, 91, 160, 719, 812, 882, 1913, 11],\n",
       " [159, 241, 525, 111, 2672, 525, 11]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[6454]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get Batch</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(sequences, pad_idx, max_length=None):\n",
    "    '''\n",
    "    Inputs:\n",
    "        sequences: list of list of tokens\n",
    "    '''\n",
    "    if max_length is None:\n",
    "        max_length = max(map(len, sequences))\n",
    "    \n",
    "    return [seq + [pad_idx]*(max_length - len(seq)) for seq in sequences]\n",
    "\n",
    "def get_batch(batch_size, train):\n",
    "    if train:\n",
    "        data = train_data\n",
    "    else:\n",
    "        data = test_data\n",
    "        \n",
    "    rand_ids = np.random.randint(0, len(data), batch_size)\n",
    "    \n",
    "    source = [data[idx][0] for idx in rand_ids]\n",
    "    target = [data[idx][1] for idx in rand_ids]\n",
    "    \n",
    "    target_in  = [[sos_idx] + sequence for sequence in target]\n",
    "    target_out = [sequence + [eos_idx] for sequence in target]\n",
    "    \n",
    "    source     = padding(source, pad_idx)\n",
    "    target_in  = padding(target_in, pad_idx)\n",
    "    target_out = padding(target_out, pad_idx)\n",
    "    \n",
    "    source     = torch.LongTensor(source).to(device)\n",
    "    target_in  = torch.LongTensor(target_in).to(device)\n",
    "    target_out = torch.LongTensor(target_out).to(device)\n",
    "    \n",
    "    return source, target_in, target_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target_in, target_out = get_batch(32, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 15]), torch.Size([32, 16]), torch.Size([32, 16]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.size(), target_in.size(), target_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Neural Network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, padding_idx):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=padding_idx)\n",
    "        self.lstm      = nn.LSTM(emb_size, hidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, batch_words):\n",
    "        '''\n",
    "        Inputs:\n",
    "            batch_words: (batch x source_len)\n",
    "        '''\n",
    "        \n",
    "        #(batch x source_len) -> (batch x source_len x emb_size)\n",
    "        embedded = self.embedding(batch_words)\n",
    "        \n",
    "        output, hidden = self.lstm(embedded)\n",
    "        return output\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_output, encoder_mask):\n",
    "        '''\n",
    "        Inputs:\n",
    "            hidden: (batch x hidden_size)\n",
    "            encoder_output: (batch x source_len x hidden_size)\n",
    "        '''\n",
    "        hidden = self.linear(hidden)\n",
    "        hidden = hidden.unsqueeze(2)\n",
    "        alphas = encoder_output.matmul(hidden)\n",
    "        \n",
    "        if encoder_mask is not None:\n",
    "            alphas[encoder_mask] = -1e16\n",
    "            \n",
    "        scores = F.softmax(alphas, dim=1)\n",
    "        c = (scores * encoder_output).sum(dim=1)\n",
    "        return c\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, padding_idx):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=padding_idx)\n",
    "        self.attn      = Attention(hidden_size)\n",
    "        self.gru_cell  = nn.GRUCell(emb_size + hidden_size, hidden_size)\n",
    "        self.linear    = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, batch_trans_in, encoder_output, hidden, encoder_mask=None):\n",
    "        '''\n",
    "        Inputs:\n",
    "            batch_trans_in: (batch x target_len)\n",
    "            encoder_output: (batch x source_len x hidden_size)\n",
    "            hidden: (batch x hidden_size)\n",
    "        '''\n",
    "        embedded  = self.embedding(batch_trans_in)\n",
    "        timesteps = embedded.size(1)\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for t in range(timesteps):\n",
    "            x = embedded[:, t]\n",
    "            c = self.attn(hidden, encoder_output, encoder_mask)\n",
    "            inp = torch.cat([x, c], dim=1)\n",
    "            hidden = self.gru_cell(inp, hidden)\n",
    "            output.append(hidden)\n",
    "        \n",
    "        output = torch.stack(output, dim=1)\n",
    "        logits = self.linear(output)\n",
    "        return logits.view(-1, self.vocab_size), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {value: key for key, value in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print(train=True):\n",
    "    source, _, _ = get_batch(1, train=True)\n",
    "    encoder_output = encoder(source)\n",
    "    \n",
    "    hidden = torch.zeros(1, hidden_size).to(device)\n",
    "    \n",
    "    generated = [sos_idx]\n",
    "    \n",
    "    for i in range(min_length):\n",
    "        \n",
    "        generated_in = torch.LongTensor([[generated[-1]]]).to(device)\n",
    "        \n",
    "        logit, hidden = decoder(generated_in, encoder_output, hidden)\n",
    "        next_idx = logit.max(1)[1][0].item()\n",
    "        generated.append(next_idx)\n",
    "        \n",
    "        if next_idx == eos_idx:\n",
    "            break\n",
    "            \n",
    "    source = [id2word.get(idx, \"unk\") for idx in source[0].tolist()]\n",
    "    target = [id2word.get(idx, \"unk\") for idx in generated if idx not in [sos_idx, eos_idx]]\n",
    "    \n",
    "    source = ' '.join(source)\n",
    "    target = ' '.join(target)\n",
    "    \n",
    "    print(source)\n",
    "    print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size    = 256\n",
    "hidden_size = 512\n",
    "\n",
    "encoder = Encoder(len(word2id), emb_size, hidden_size, pad_idx).to(device)\n",
    "decoder = Decoder(len(word2id), emb_size, hidden_size, pad_idx).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the skull is gone .\n",
      "kimberly norma shoe murders lied ghosts instead hands jazz kane trigger tor executed executed boss mutual\n"
     ]
    }
   ],
   "source": [
    "_print(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 8.681123733520508\n",
      "remember when you asked me what my idea of normal was ?\n",
      "kimberly norma shoe rose prayer germans autograph calls butter reality given take catching loyal involved serves\n",
      "------\n",
      "you should know something .\n",
      "kimberly norma shoe affair affair seem mexico bingo spoke lovely east burger patients print print franklin\n",
      "-------\n",
      "\n",
      "Epoch: 1. Loss: 3.410186290740967\n",
      "you have to add some <unk> and stuff . maybe they run out of gas .\n",
      "i m not going to be a <unk> .\n",
      "------\n",
      "hah <unk> great video huh ?\n",
      "i don t know .\n",
      "-------\n",
      "\n",
      "Epoch: 2. Loss: 3.4915847778320312\n",
      "close . . . there\n",
      "what ?\n",
      "------\n",
      "what s today ?\n",
      "i don t know .\n",
      "-------\n",
      "\n",
      "Epoch: 3. Loss: 3.0645124912261963\n",
      "<unk> <unk> ?\n",
      "<unk> .\n",
      "------\n",
      "your equipment has <unk> out again . . . .\n",
      "i m not . . .\n",
      "-------\n",
      "\n",
      "Epoch: 4. Loss: 2.7267518043518066\n",
      "no . . . it s in shadow .\n",
      "i know .\n",
      "------\n",
      "<unk> is down .\n",
      "i don t know .\n",
      "-------\n",
      "\n",
      "Epoch: 5. Loss: 2.7404611110687256\n",
      "i don t care to bargain .\n",
      "i know .\n",
      "------\n",
      "he said something about a girl\n",
      "i know you re not funny .\n",
      "-------\n",
      "\n",
      "Epoch: 6. Loss: 2.4386532306671143\n",
      "nonsense . she s one of the <unk> girls i know .\n",
      "she s a <unk> ?\n",
      "------\n",
      "what was that word young man ! ?\n",
      "i don t know . i m sorry .\n",
      "-------\n",
      "\n",
      "Epoch: 7. Loss: 2.4102823734283447\n",
      "sam ! i was just telling a few about your old man .\n",
      "i m sorry .\n",
      "------\n",
      "it was just there .\n",
      "no way it was .\n",
      "-------\n",
      "\n",
      "Epoch: 8. Loss: 2.210808277130127\n",
      "your life will never be the same .\n",
      "i don t care .\n",
      "------\n",
      "you re all through with this now ?\n",
      "i m not going to tell you .\n",
      "-------\n",
      "\n",
      "Epoch: 9. Loss: 2.140035629272461\n",
      "one to five ?\n",
      "yes .\n",
      "------\n",
      "your court order dr . <unk> .\n",
      "i know that .\n",
      "-------\n",
      "\n",
      "Epoch: 10. Loss: 2.0989885330200195\n",
      "what are you looking at ?\n",
      "i m not sure i can t tell you .\n",
      "------\n",
      "you always carry these ?\n",
      "yes .\n",
      "-------\n",
      "\n",
      "Epoch: 11. Loss: 1.9199161529541016\n",
      "it hurts too much .\n",
      "i know .\n",
      "------\n",
      "enough is enough daniel . where exactly are we ?\n",
      "i m a writer at a <unk> .\n",
      "-------\n",
      "\n",
      "Epoch: 12. Loss: 1.7293199300765991\n",
      "their life <unk> is a hundred and thirty .\n",
      "that s <unk> .\n",
      "------\n",
      "hildy !\n",
      "you re wrong !\n",
      "-------\n",
      "\n",
      "Epoch: 13. Loss: 1.6071876287460327\n",
      "what the fuck !\n",
      "i m gonna go for a hundred miles .\n",
      "------\n",
      "so tell me everything . details . i like details .\n",
      "i ll tell you .\n",
      "-------\n",
      "\n",
      "Epoch: 14. Loss: 1.5248407125473022\n",
      "i m familiar with how a <unk> <unk> is handled .\n",
      "oh .\n",
      "------\n",
      "this guy is gonna run to the fbi .\n",
      "i ll wait for you as a happy time .\n",
      "-------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "batch_size = 128\n",
    "with mlflow.start_run():\n",
    "    for epoch in range(15):\n",
    "        for batch_idx in range(len(train_data) // batch_size):\n",
    "\n",
    "            source, target_in, target_out = get_batch(batch_size, train=True)\n",
    "            encoder_output = encoder(source)\n",
    "            encoder_mask = source == pad_idx\n",
    "            hidden = torch.zeros(batch_size, hidden_size).to(device)\n",
    "            logit, hidden = decoder(target_in, encoder_output, hidden, encoder_mask)\n",
    "\n",
    "            target_out = target_out.view(-1)\n",
    "            decoder_mask = target_out != pad_idx\n",
    "            decoder_mask = decoder_mask\n",
    "\n",
    "            loss = criterion(logit[decoder_mask], target_out[decoder_mask])\n",
    "\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            decoder_optimizer.step()\n",
    "            encoder_optimizer.step()\n",
    "\n",
    "            if batch_idx % 1000 == 0:\n",
    "                print(\"Epoch: %s. Loss: %s\" % (epoch, loss.item()))\n",
    "                _print(True)\n",
    "                print('------')\n",
    "                _print(False)\n",
    "                print('-------')\n",
    "                print()\n",
    "                \n",
    "                mlflow.log_metric(\"loss\", np.double(loss.item()))\n",
    "\n",
    "    mlflow.pytorch.save_model(encoder, \"encoder\")\n",
    "    mlflow.pytorch.save_model(decoder, \"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-06 20:13:23 +0600] [3173104] [INFO] Starting gunicorn 20.1.0\n",
      "[2021-09-06 20:13:23 +0600] [3173104] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2021-09-06 20:13:23 +0600] [3173104] [ERROR] Retrying in 1 second.\n",
      "[2021-09-06 20:13:24 +0600] [3173104] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2021-09-06 20:13:24 +0600] [3173104] [ERROR] Retrying in 1 second.\n",
      "[2021-09-06 20:13:25 +0600] [3173104] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2021-09-06 20:13:25 +0600] [3173104] [ERROR] Retrying in 1 second.\n",
      "[2021-09-06 20:13:26 +0600] [3173104] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2021-09-06 20:13:26 +0600] [3173104] [ERROR] Retrying in 1 second.\n",
      "[2021-09-06 20:13:27 +0600] [3173104] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2021-09-06 20:13:27 +0600] [3173104] [ERROR] Retrying in 1 second.\n",
      "[2021-09-06 20:13:28 +0600] [3173104] [ERROR] Can't connect to ('127.0.0.1', 5000)\n",
      "Running the mlflow server failed. Please see the logs above for details.\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Hello, my name is Zuzee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepr(a):\n",
    "    a = unicodeToAscii(a)\n",
    "    a = normalizeString(a)\n",
    "    a = a.split()\n",
    "    a = [word2id.get(word, unk_idx) for word in a]\n",
    "    a = torch.LongTensor(a).to(device)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = [word2id.get(word, unk_idx) for word in a]\n",
    "#a = torch.LongTensor(a).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = a + [pad_idx]*(min_length - len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = torch.LongTensor(a).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(source1):\n",
    "    source1 = prepr(source1)\n",
    "    seq = source1.unsqueeze(0)\n",
    "    encoder_output = encoder(seq)\n",
    "    \n",
    "    hidden = torch.zeros(1, hidden_size).to(device)\n",
    "    \n",
    "    generated = [sos_idx]\n",
    "    \n",
    "    for i in range(min_length):\n",
    "        \n",
    "        generated_in = torch.LongTensor([[generated[-1]]]).to(device)\n",
    "        \n",
    "        logit, hidden = decoder(generated_in, encoder_output, hidden)\n",
    "        next_idx = logit.max(1)[1][0].item()\n",
    "        generated.append(next_idx)\n",
    "        \n",
    "        if next_idx == eos_idx:\n",
    "            break\n",
    "            \n",
    "    seq = [id2word.get(idx, \"unk\") for idx in seq[0].tolist()]\n",
    "    target = [id2word.get(idx, \"unk\") for idx in generated if idx not in [sos_idx, eos_idx]]\n",
    "    \n",
    "    seq = ' '.join(seq)\n",
    "    target = ' '.join(target)\n",
    "    \n",
    "    print(seq)\n",
    "    print(target)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello my name is <unk>\n",
      "hello sir .\n"
     ]
    }
   ],
   "source": [
    "v = eval(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id2word.pkl', 'wb') as f:\n",
    "        pickle.dump(id2word, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word2id.pkl', 'wb') as f:\n",
    "        pickle.dump(word2id, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
